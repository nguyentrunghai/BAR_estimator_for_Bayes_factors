{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.mixture import GaussianMixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_values_from_trace(model, trace, thin=1, burn=0):\n",
    "    \"\"\"\n",
    "    :param model: pymc3 model\n",
    "    :param trace: pymc3 trace object\n",
    "    :param thin: int\n",
    "    :param burn: int, number of steps to exclude\n",
    "    :return: dict: varname --> ndarray\n",
    "    \"\"\"\n",
    "    varnames = [var.name for var in model.vars]\n",
    "    trace_values = {var: trace.get_values(var, thin=thin, burn=burn) for var in varnames}\n",
    "    return trace_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussMix(object):\n",
    "    def __init__(self, n_components, covariance_type=\"diag\"):\n",
    "        self._n_components = n_components\n",
    "        self._vars = []\n",
    "        self._gm = GaussianMixture(n_components=self._n_components, covariance_type=covariance_type)\n",
    "    \n",
    "    def fit(self, sample_dict):\n",
    "        \"\"\"\n",
    "        :param sample_dict: dict, var --> 1d array\n",
    "        \"\"\"\n",
    "        self._vars = list(sample_dict.keys())\n",
    "        X_train = self._dict_to_array(sample_dict)\n",
    "        self._gm.fit(X_train)\n",
    "        return self\n",
    "    \n",
    "    def score_samples(self, sample_dict):\n",
    "        X = self._dict_to_array(sample_dict)\n",
    "        logp = self._gm.score_samples(X)\n",
    "        return logp\n",
    "    \n",
    "    def sample(self, n_samples=1):\n",
    "        X = self._gm.sample(n_samples=n_samples)\n",
    "        X = X[0]\n",
    "        X_dict = {}\n",
    "        for i, v in enumerate(self._vars):\n",
    "            X_dict[v] = X[:, i]\n",
    "        return X_dict\n",
    "    \n",
    "    def get_vars(self):\n",
    "        return self._vars\n",
    "    \n",
    "    def get_model(self):\n",
    "        return self._gm\n",
    "    \n",
    "    def get_gm_fited_params(self):\n",
    "        weights = self._gm.weights_\n",
    "        means = self._gm.means_\n",
    "        covariances = self._gm.covariances_\n",
    "        \n",
    "        results = {}\n",
    "        for i, v in enumerate(self._vars):\n",
    "            results[v] = {}\n",
    "            results[v][\"weights\"] = weights\n",
    "            results[v][\"means\"] = [means[j][i] for j in range(self._n_components)]\n",
    "            results[v][\"sigmas\"] = [np.sqrt(covariances[j][i]) for j in range(self._n_components)]\n",
    "        return results\n",
    "    \n",
    "    def get_n_components(self):\n",
    "        return self._n_components\n",
    "    \n",
    "    def _dict_to_array(self, sample_dict):\n",
    "        X = [sample_dict[v] for v in self._vars]\n",
    "        X = np.stack(X, axis=1)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_normal_pdf(mu, sigma, y):\n",
    "    sigma2 = sigma * sigma\n",
    "    res = - 0.5 * np.log(2 * np.pi * sigma2) - (0.5 / sigma2) * (y - mu) ** 2\n",
    "    return res\n",
    "\n",
    "\n",
    "def log_mult_normal_pdf(mu_vec, sigma_vec, y_vec):\n",
    "    logp = 0.\n",
    "    for mu, sigma, y in zip(mu_vec, sigma_vec, y_vec):\n",
    "        logp += log_normal_pdf(mu, sigma, y)\n",
    "    return logp\n",
    "\n",
    "\n",
    "def log_gm_pdf(weights, mu_mat, sigma_mat, y_vec):\n",
    "    \"\"\"\n",
    "    :param weights: ndarray of shape (n_components,)\n",
    "    :param mu_mat: ndarray of shape (n_components, n_features)\n",
    "    :param sigma_mat: ndarray of shape (n_components, n_features)\n",
    "    :param y_vec: ndarray of shape (n_features,)\n",
    "    \"\"\"\n",
    "    n_components = mu_mat.shape[0]\n",
    "    assert n_components == len(weights), \"wrong weight len\"\n",
    "    \n",
    "    prop = 0.\n",
    "    for i, w in enumerate(weights):\n",
    "        mu_vec = mu_mat[i, :]\n",
    "        sigma_vec = sigma_mat[i, :]\n",
    "        prop += w * np.exp(log_mult_normal_pdf(mu_vec, sigma_vec, y_vec))\n",
    "    logp = np.log(prop)\n",
    "    return logp\n",
    "\n",
    "\n",
    "def make_param_mats(var_names, gm_fited_params):\n",
    "    n_features = len(var_names)\n",
    "    n_components = len(gm_fited_params[var_names[0]][\"weights\"])\n",
    "    \n",
    "    weights = gm_fited_params[var_names[0]][\"weights\"]\n",
    "    mean_mat = np.zeros([n_components, n_features])\n",
    "    sigma_mat = np.zeros([n_components, n_features])\n",
    "    \n",
    "    for i in range(n_features):\n",
    "        for j in range(n_components):\n",
    "            mean_mat[j, i] = gm_fited_params[var_names[i]][\"means\"][j]\n",
    "            sigma_mat[j, i] = gm_fited_params[var_names[i]][\"sigmas\"][j]\n",
    "    return weights, mean_mat, sigma_mat\n",
    "\n",
    "\n",
    "def logp_gm(sample_dict, gm_fited_params):\n",
    "    var_names = list(sample_dict)\n",
    "    weights, mu_mat, sigma_mat = make_param_mats(var_names, gm_fited_params)\n",
    "    \n",
    "    nsamples = len(sample_dict[var_names[0]])\n",
    "    \n",
    "    logps = []\n",
    "    for i in range(nsamples):\n",
    "        y_vec = [sample_dict[v][i] for v in var_names]\n",
    "        y_vec = np.array(y_vec)\n",
    "        \n",
    "        logps.append(log_gm_pdf(weights, mu_mat, sigma_mat, y_vec))\n",
    "    return np.array(logps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pickle.load(open(\"data/pm_model.pickle\", \"rb\"), encoding=\"latin1\")\n",
    "trace = pickle.load(open(\"data/trace_obj.pickle\", \"rb\"), encoding=\"latin1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = get_values_from_trace(model, trace, thin=10, burn=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['P0_interval__', 'Ls_log__', 'rho_interval__', 'DeltaG1_interval__', 'DeltaDeltaG_interval__', 'DeltaH1_interval__', 'DeltaH2_interval__', 'DeltaH_0_interval__', 'log_sigma_interval__'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_redun = [\"DeltaDeltaG_interval__\", \"DeltaH2_interval__\", \"rho_interval__\"]\n",
    "sample_redun = {v: sample[v] for v in vars_redun}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.GaussMix at 0x1c248637f0>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gm = GaussMix(n_components=2)\n",
    "gm.fit(sample_redun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_names = gm.get_vars()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DeltaDeltaG_interval__': {'weights': array([0.61743209, 0.38256791]),\n",
       "  'means': [-2.0987785802756624, -2.072725326086235],\n",
       "  'sigmas': [0.011334851006068677, 0.012968816658843139]},\n",
       " 'DeltaH2_interval__': {'weights': array([0.61743209, 0.38256791]),\n",
       "  'means': [-0.03600911484325556, -0.04360622257306616],\n",
       "  'sigmas': [0.004091506001760568, 0.0052164789017458265]},\n",
       " 'rho_interval__': {'weights': array([0.61743209, 0.38256791]),\n",
       "  'means': [-1.6878444101523138, -1.8079744597974272],\n",
       "  'sigmas': [0.05067689854942538, 0.06244811469778752]}}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gm_params = gm.get_gm_fited_params()\n",
    "gm_params "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DeltaDeltaG_interval__': array([-2.10588629, -2.1319254 , -2.09933495, -2.10669531, -2.08521986,\n",
       "        -2.11142978, -2.09508337, -2.0940456 , -2.06823434, -2.09333465]),\n",
       " 'DeltaH2_interval__': array([-0.03345192, -0.03537208, -0.03189837, -0.03412944, -0.03299124,\n",
       "        -0.03660914, -0.03200123, -0.03110118, -0.04213963, -0.05291524]),\n",
       " 'rho_interval__': array([-1.66723132, -1.67807022, -1.73722825, -1.71262908, -1.68888036,\n",
       "        -1.66292375, -1.67674359, -1.71731014, -1.91959383, -1.64624435])}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = gm.sample(n_samples=10)\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.24760389, 5.41545617, 8.74600932, 9.2540315 , 8.74616119,\n",
       "       8.96769106, 9.16635635, 8.75098411, 6.96002973, 2.61373642])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gm.score_samples(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.24760389, 5.41545617, 8.74600932, 9.2540315 , 8.74616119,\n",
       "       8.96769106, 9.16635635, 8.75098411, 6.96002973, 2.61373642])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logp_gm(X_test, gm_params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
