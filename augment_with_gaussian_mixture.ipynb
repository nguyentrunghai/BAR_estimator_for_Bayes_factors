{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.mixture import GaussianMixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_values_from_trace(model, trace, thin=1, burn=0):\n",
    "    \"\"\"\n",
    "    :param model: pymc3 model\n",
    "    :param trace: pymc3 trace object\n",
    "    :param thin: int\n",
    "    :param burn: int, number of steps to exclude\n",
    "    :return: dict: varname --> ndarray\n",
    "    \"\"\"\n",
    "    varnames = [var.name for var in model.vars]\n",
    "    trace_values = {var: trace.get_values(var, thin=thin, burn=burn) for var in varnames}\n",
    "    return trace_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussMix(object):\n",
    "    def __init__(self, n_components, covariance_type=\"diag\"):\n",
    "        self._n_components = n_components\n",
    "        self._vars = []\n",
    "        self._gm = GaussianMixture(n_components=self._n_components, covariance_type=covariance_type)\n",
    "    \n",
    "    def fit(self, sample_dict):\n",
    "        \"\"\"\n",
    "        :param sample_dict: dict, var --> 1d array\n",
    "        \"\"\"\n",
    "        self._vars = list(sample_dict.keys())\n",
    "        X_train = self._dict_to_array(sample_dict)\n",
    "        self._gm.fit(X_train)\n",
    "        return self\n",
    "    \n",
    "    def score_samples(self, sample_dict):\n",
    "        X = self._dict_to_array(sample_dict)\n",
    "        logp = self._gm.score_samples(X)\n",
    "        return logp\n",
    "    \n",
    "    def sample(self, n_samples=1):\n",
    "        X = self._gm.sample(n_samples=n_samples)\n",
    "        X = X[0]\n",
    "        X_dict = {}\n",
    "        for i, v in enumerate(self._vars):\n",
    "            X_dict[v] = X[:, i]\n",
    "        return X_dict\n",
    "    \n",
    "    def get_vars(self):\n",
    "        return self._vars\n",
    "    \n",
    "    def get_model(self):\n",
    "        return self._gm\n",
    "    \n",
    "    def get_gm_fited_params(self):\n",
    "        weights = self._gm.weights_\n",
    "        means = self._gm.means_\n",
    "        covariances = self._gm.covariances_\n",
    "        \n",
    "        results = {}\n",
    "        for i, v in enumerate(self._vars):\n",
    "            results[v] = {}\n",
    "            results[v][\"weights\"] = weights\n",
    "            results[v][\"means\"] = [means[j][i] for j in range(self._n_components)]\n",
    "            results[v][\"sigmas\"] = [np.sqrt(covariances[j][i]) for j in range(self._n_components)]\n",
    "        return results\n",
    "    \n",
    "    def get_n_components(self):\n",
    "        return self._n_components\n",
    "    \n",
    "    def _dict_to_array(self, sample_dict):\n",
    "        X = [sample_dict[v] for v in self._vars]\n",
    "        X = np.stack(X, axis=1)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pickle.load(open(\"data/pm_model.pickle\", \"rb\"), encoding=\"latin1\")\n",
    "trace = pickle.load(open(\"data/trace_obj.pickle\", \"rb\"), encoding=\"latin1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = get_values_from_trace(model, trace, thin=10, burn=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['P0_interval__', 'Ls_log__', 'rho_interval__', 'DeltaG1_interval__', 'DeltaDeltaG_interval__', 'DeltaH1_interval__', 'DeltaH2_interval__', 'DeltaH_0_interval__', 'log_sigma_interval__'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_redun = [\"DeltaDeltaG_interval__\", \"DeltaH2_interval__\", \"rho_interval__\"]\n",
    "sample_redun = {v: sample[v] for v in vars_redun}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.GaussMix at 0x1c248637f0>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gm = GaussMix(n_components=2)\n",
    "gm.fit(sample_redun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DeltaDeltaG_interval__', 'DeltaH2_interval__', 'rho_interval__']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gm.get_vars()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DeltaDeltaG_interval__': array([-2.0999259 , -2.11464709, -2.06542341, -2.07845874]),\n",
       " 'DeltaH2_interval__': array([-0.03549078, -0.04313791, -0.04534546, -0.04442305]),\n",
       " 'rho_interval__': array([-1.80280112, -1.7311501 , -1.87681932, -1.8216553 ])}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gm.sample(n_samples=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DeltaDeltaG_interval__': {'weights': array([0.6158551, 0.3841449]),\n",
       "  'means': [-2.0988126610978113, -2.0727776419495987],\n",
       "  'sigmas': [0.01132260032867812, 0.012977175461882056]},\n",
       " 'DeltaH2_interval__': {'weights': array([0.6158551, 0.3841449]),\n",
       "  'means': [-0.03600000421669944, -0.04358964097384545],\n",
       "  'sigmas': [0.0040884011102282885, 0.005217660743037346]},\n",
       " 'rho_interval__': {'weights': array([0.6158551, 0.3841449]),\n",
       "  'means': [-1.6876925899280435, -1.8077246982554414],\n",
       "  'sigmas': [0.050620789169130875, 0.06248262122442569]}}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gm.get_gm_fited_params()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
