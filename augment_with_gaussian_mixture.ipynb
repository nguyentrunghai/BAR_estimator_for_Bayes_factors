{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.mixture import GaussianMixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_values_from_trace(model, trace, thin=1, burn=0):\n",
    "    \"\"\"\n",
    "    :param model: pymc3 model\n",
    "    :param trace: pymc3 trace object\n",
    "    :param thin: int\n",
    "    :param burn: int, number of steps to exclude\n",
    "    :return: dict: varname --> ndarray\n",
    "    \"\"\"\n",
    "    varnames = [var.name for var in model.vars]\n",
    "    trace_values = {var: trace.get_values(var, thin=thin, burn=burn) for var in varnames}\n",
    "    return trace_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussMix(object):\n",
    "    def __init__(self, n_components, covariance_type=\"diag\"):\n",
    "        self._n_components = n_components\n",
    "        self._vars = []\n",
    "        self._gm = GaussianMixture(n_components=self._n_components, covariance_type=covariance_type)\n",
    "    \n",
    "    def fit(self, sample_dict):\n",
    "        \"\"\"\n",
    "        :param sample_dict: dict, var --> 1d array\n",
    "        \"\"\"\n",
    "        self._vars = list(sample_dict.keys())\n",
    "        X_train = self._dict_to_array(sample_dict)\n",
    "        self._gm.fit(X_train)\n",
    "        return self\n",
    "    \n",
    "    def score_samples(self, sample_dict):\n",
    "        \"\"\"return logp\"\"\"\n",
    "        X = self._dict_to_array(sample_dict)\n",
    "        logp = self._gm.score_samples(X)\n",
    "        return logp\n",
    "    \n",
    "    def sample(self, n_samples=1):\n",
    "        X = self._gm.sample(n_samples=n_samples)\n",
    "        X = X[0]\n",
    "        X_dict = {}\n",
    "        for i, v in enumerate(self._vars):\n",
    "            X_dict[v] = X[:, i]\n",
    "        return X_dict\n",
    "    \n",
    "    def get_vars(self):\n",
    "        return self._vars\n",
    "    \n",
    "    def get_model(self):\n",
    "        return self._gm\n",
    "    \n",
    "    def get_gm_fited_params(self):\n",
    "        weights = self._gm.weights_\n",
    "        means = self._gm.means_\n",
    "        covariances = self._gm.covariances_\n",
    "        \n",
    "        results = {}\n",
    "        for i, v in enumerate(self._vars):\n",
    "            results[v] = {}\n",
    "            results[v][\"weights\"] = weights\n",
    "            results[v][\"means\"] = [means[j][i] for j in range(self._n_components)]\n",
    "            results[v][\"sigmas\"] = [np.sqrt(covariances[j][i]) for j in range(self._n_components)]\n",
    "        return results\n",
    "    \n",
    "    def get_n_components(self):\n",
    "        return self._n_components\n",
    "    \n",
    "    def _dict_to_array(self, sample_dict):\n",
    "        X = [sample_dict[v] for v in self._vars]\n",
    "        X = np.stack(X, axis=1)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_normal_pdf(mu, sigma, y):\n",
    "    sigma2 = sigma * sigma\n",
    "    res = - 0.5 * np.log(2 * np.pi * sigma2) - (0.5 / sigma2) * (y - mu) ** 2\n",
    "    return res\n",
    "\n",
    "\n",
    "def log_mult_normal_pdf(mu_vec, sigma_vec, y_vec):\n",
    "    logp = 0.\n",
    "    for mu, sigma, y in zip(mu_vec, sigma_vec, y_vec):\n",
    "        logp += log_normal_pdf(mu, sigma, y)\n",
    "    return logp\n",
    "\n",
    "\n",
    "def log_gm_pdf(weights, mu_mat, sigma_mat, y_vec):\n",
    "    \"\"\"\n",
    "    :param weights: ndarray of shape (n_components,)\n",
    "    :param mu_mat: ndarray of shape (n_components, n_features)\n",
    "    :param sigma_mat: ndarray of shape (n_components, n_features)\n",
    "    :param y_vec: ndarray of shape (n_features,)\n",
    "    \"\"\"\n",
    "    n_components = mu_mat.shape[0]\n",
    "    assert n_components == len(weights), \"wrong weight len\"\n",
    "    \n",
    "    prop = 0.\n",
    "    for i, w in enumerate(weights):\n",
    "        mu_vec = mu_mat[i, :]\n",
    "        sigma_vec = sigma_mat[i, :]\n",
    "        prop += w * np.exp(log_mult_normal_pdf(mu_vec, sigma_vec, y_vec))\n",
    "    logp = np.log(prop)\n",
    "    return logp\n",
    "\n",
    "\n",
    "def make_param_mats(var_names, gm_fited_params):\n",
    "    n_features = len(var_names)\n",
    "    n_components = len(gm_fited_params[var_names[0]][\"weights\"])\n",
    "    \n",
    "    weights = gm_fited_params[var_names[0]][\"weights\"]\n",
    "    mean_mat = np.zeros([n_components, n_features])\n",
    "    sigma_mat = np.zeros([n_components, n_features])\n",
    "    \n",
    "    for i in range(n_features):\n",
    "        for j in range(n_components):\n",
    "            mean_mat[j, i] = gm_fited_params[var_names[i]][\"means\"][j]\n",
    "            sigma_mat[j, i] = gm_fited_params[var_names[i]][\"sigmas\"][j]\n",
    "    return weights, mean_mat, sigma_mat\n",
    "\n",
    "\n",
    "def logp_gm(sample_dict, gm_fited_params):\n",
    "    var_names = list(sample_dict)\n",
    "    weights, mu_mat, sigma_mat = make_param_mats(var_names, gm_fited_params)\n",
    "    \n",
    "    nsamples = len(sample_dict[var_names[0]])\n",
    "    \n",
    "    logps = []\n",
    "    for i in range(nsamples):\n",
    "        y_vec = [sample_dict[v][i] for v in var_names]\n",
    "        y_vec = np.array(y_vec)\n",
    "        \n",
    "        logps.append(log_gm_pdf(weights, mu_mat, sigma_mat, y_vec))\n",
    "    return np.array(logps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pickle.load(open(\"data/pm_model.pickle\", \"rb\"), encoding=\"latin1\")\n",
    "trace = pickle.load(open(\"data/trace_obj.pickle\", \"rb\"), encoding=\"latin1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = get_values_from_trace(model, trace, thin=10, burn=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['P0_interval__', 'Ls_log__', 'rho_interval__', 'DeltaG1_interval__', 'DeltaDeltaG_interval__', 'DeltaH1_interval__', 'DeltaH2_interval__', 'DeltaH_0_interval__', 'log_sigma_interval__'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_redun = [\"DeltaDeltaG_interval__\", \"DeltaH2_interval__\", \"rho_interval__\"]\n",
    "sample_redun = {v: sample[v] for v in vars_redun}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        , -0.66418762],\n",
       "       [-0.66418762,  1.        ]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef(sample_redun[\"DeltaDeltaG_interval__\"], sample_redun[\"DeltaH2_interval__\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        , -0.81507442],\n",
       "       [-0.81507442,  1.        ]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef(sample_redun[\"DeltaDeltaG_interval__\"], sample_redun[\"rho_interval__\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.63664573],\n",
       "       [0.63664573, 1.        ]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef(sample_redun[\"DeltaH2_interval__\"], sample_redun[\"rho_interval__\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.GaussMix at 0x1c1f726898>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gm = GaussMix(n_components=2)\n",
    "gm.fit(sample_redun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DeltaDeltaG_interval__', 'DeltaH2_interval__', 'rho_interval__']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_names = gm.get_vars()\n",
    "var_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DeltaDeltaG_interval__': {'weights': array([0.3841449, 0.6158551]),\n",
       "  'means': [-2.0727776419495987, -2.0988126610978113],\n",
       "  'sigmas': [0.012977175461882056, 0.01132260032867812]},\n",
       " 'DeltaH2_interval__': {'weights': array([0.3841449, 0.6158551]),\n",
       "  'means': [-0.04358964097384545, -0.03600000421669944],\n",
       "  'sigmas': [0.005217660743037346, 0.0040884011102282885]},\n",
       " 'rho_interval__': {'weights': array([0.3841449, 0.6158551]),\n",
       "  'means': [-1.8077246982554414, -1.6876925899280435],\n",
       "  'sigmas': [0.06248262122442569, 0.050620789169130875]}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gm_params = gm.get_gm_fited_params()\n",
    "gm_params "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing if it runs correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DeltaDeltaG_interval__': array([-2.05724518, -2.07888896, -2.07351354, -2.0741865 , -2.06958531,\n",
       "        -2.07517282, -2.10353689, -2.08948616, -2.09619999, -2.08921003]),\n",
       " 'DeltaH2_interval__': array([-0.04687381, -0.04662911, -0.04126353, -0.04252729, -0.03772795,\n",
       "        -0.0349692 , -0.03706326, -0.03999489, -0.03443599, -0.03906427]),\n",
       " 'rho_interval__': array([-1.76702403, -1.78057609, -1.84396141, -1.80886029, -1.80720863,\n",
       "        -1.64473731, -1.69814697, -1.7735829 , -1.62355458, -1.73398754])}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = gm.sample(n_samples=10)\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.53313439, 8.29027972, 8.39159228, 8.63723898, 8.00946794,\n",
       "       7.18812068, 9.58255798, 8.14840344, 8.82037984, 8.80592661])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gm.score_samples(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.53313439, 8.29027972, 8.39159228, 8.63723898, 8.00946794,\n",
       "       7.18812068, 9.58255798, 8.14840344, 8.82037984, 8.80592661])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logp_gm(X_test, gm_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying different `n_components` and `covariance_type`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `n_components = 2`,  `covariance_type=full`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.GaussMix at 0x1c24256518>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gm = GaussMix(n_components=2, covariance_type=\"full\")\n",
    "gm.fit(sample_redun)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
