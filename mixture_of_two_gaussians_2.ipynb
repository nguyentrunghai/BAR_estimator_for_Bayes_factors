{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pymc3 as pm\n",
    "import theano.tensor as tt\n",
    "import pymbar\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "from _BAR_estimator import get_values_from_trace\n",
    "from _BAR_estimator import bayes_factor_smc\n",
    "from _BAR_estimator import fit_normal_trace\n",
    "from _BAR_estimator import draw_normal_samples\n",
    "from _BAR_estimator import pot_ener_normal_aug\n",
    "from _BAR_estimator import pot_ener\n",
    "from _BAR_estimator import bootstrap_BAR\n",
    "from _BAR_estimator import fit_uniform_trace\n",
    "from _BAR_estimator import draw_uniform_samples\n",
    "from _BAR_estimator import pot_ener_uniform_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 2039\n",
    "SIZE = 50\n",
    "\n",
    "SMC_STEPS = 100000\n",
    "MET_STEPS = 100000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_mixture(mu1=0, sigma1=1, mu2=0, sigma2=1,\n",
    "                     rho=0.5, size=100, random_state=None):\n",
    "    rnd = np.random.RandomState(random_state)\n",
    "    x = []\n",
    "    for _ in range(size):\n",
    "        if rnd.rand() < rho:\n",
    "            x.append(rnd.normal(loc=mu1, scale=sigma1))\n",
    "        else:\n",
    "            x.append(rnd.normal(loc=mu2, scale=sigma2))\n",
    "    return np.array(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = gaussian_mixture(mu1=0, sigma1=1, mu2=3, sigma2=1, rho=0.5, size=SIZE, random_state=SEED)\n",
    "sns.distplot(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as model_m1:\n",
    "    mu = pm.Uniform(\"mu\", lower=-10, upper=10)\n",
    "    sigma = pm.Uniform(\"sigma\", lower=0.1, upper=5)\n",
    "    obs = pm.Normal(\"obs\", mu=mu, sigma=1, observed=x)\n",
    "\n",
    "print(model_m1.vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as model_m2:\n",
    "    w = pm.floatX([.5, .5])\n",
    "    sigmas = pm.floatX([1., 1])\n",
    "    \n",
    "    mu = pm.Uniform(\"mu\", lower=-10, upper=10)\n",
    "    dmu = pm.Uniform(\"dmu\", lower=0, upper=10)\n",
    "    means = tt.zeros([2])\n",
    "    means = tt.set_subtensor(means[0], mu)\n",
    "    means = tt.set_subtensor(means[1], mu + dmu)\n",
    "    \n",
    "    sigma1 = pm.Uniform(\"sigma1\", lower=0.1, upper=5)\n",
    "    sigma2 = pm.Uniform(\"sigma2\", lower=0.1, upper=5)\n",
    "    sigmas = tt.zeros([2])\n",
    "    sigmas = tt.set_subtensor(sigmas[0], sigma1)\n",
    "    sigmas = tt.set_subtensor(sigmas[1], sigma2)\n",
    "    \n",
    "    obs = pm.NormalMixture(\"obs\", w=w, mu=means, sigma=sigmas, observed=x)\n",
    "\n",
    "print(model_m2.vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequential Monte Carlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model_m1:\n",
    "    trace_m1 = pm.sample(SMC_STEPS, step=pm.SMC())\n",
    "pm.traceplot(trace_m1[::10])\n",
    "\n",
    "print(\"Log10 marginal likelihood: %0.5f\" %(np.log10(model_m1.marginal_likelihood)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model_m2:\n",
    "    trace_m2 = pm.sample(SMC_STEPS, step=pm.SMC())\n",
    "pm.traceplot(trace_m2[::10])\n",
    "\n",
    "print(\"Log10 marginal likelihood: %0.5f\" %(np.log10(model_m2.marginal_likelihood)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bf_smc_2_vs_1 = bayes_factor_smc(model_m1, model_m2)\n",
    "print(\"Log10 of Bayes factor model m2 over model m1: %0.5f\" % bf_smc_2_vs_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BAR estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bayes_factor_uniform_aug(model_ini, sample_ini, model_fin, sample_fin, bootstrap=None):\n",
    "    \n",
    "    lower_upper_fin = fit_uniform_trace(sample_fin)\n",
    "    lower_upper_fin = {\"dmu_interval__\": lower_upper_fin[\"dmu_interval__\"],\n",
    "                       \"sigma2_interval__\": lower_upper_fin[\"sigma2_interval__\"]}\n",
    "    \n",
    "    # potential for sample drawn from i estimated at state i\n",
    "    nsamples_ini = len(sample_ini[\"mu_interval__\"])\n",
    "    sample_aug_ini = draw_uniform_samples(lower_upper_fin, nsamples_ini)\n",
    "    u_i_i = pot_ener_uniform_aug(sample_ini, model_ini, sample_aug_ini, lower_upper_fin)\n",
    "    \n",
    "    # potential for sample drawn from i estimated at state f\n",
    "    sample_ini_comb = {\"mu_interval__\": sample_ini[\"mu_interval__\"],\n",
    "                       \"sigma1_interval__\": sample_ini[\"sigma_interval__\"]}\n",
    "    sample_ini_comb.update(sample_aug_ini)\n",
    "    u_i_f = pot_ener(sample_ini_comb, model_fin)\n",
    "    \n",
    "    # potential for sample drawn from f estimated at state f\n",
    "    u_f_f = pot_ener(sample_fin, model_fin)\n",
    "    \n",
    "    # potential for sample drawn from f estimated at state i\n",
    "    sample_fin_split = {\"mu_interval__\": sample_fin[\"mu_interval__\"], \n",
    "                        \"sigma_interval__\": sample_fin[\"sigma1_interval__\"]}\n",
    "    sample_aug_fin = {\"dmu_interval__\": sample_fin[\"dmu_interval__\"], \n",
    "                      \"sigma2_interval__\": sample_fin[\"sigma2_interval__\"]}\n",
    "    u_f_i = pot_ener_uniform_aug(sample_fin_split, model_ini, sample_aug_fin, lower_upper_fin)\n",
    "    \n",
    "    w_F = u_i_f - u_i_i\n",
    "    w_R = u_f_i - u_f_f\n",
    "\n",
    "    delta_F = pymbar.BAR(w_F, w_R, compute_uncertainty=False, relative_tolerance=1e-12, verbose=True)\n",
    "    bf = -delta_F\n",
    "\n",
    "    if bootstrap is None:\n",
    "        print(\"log10(bf) = %0.5f\" % (bf *np.log10(np.e)))\n",
    "        return bf\n",
    "    else:\n",
    "        print(\"Running %d bootstraps to estimate error.\" % bootstrap)\n",
    "        bf_err = bootstrap_BAR(w_F, w_R, bootstrap)\n",
    "        print(\"log10(bf) = %0.5f +/- %0.5f\" % (bf * np.log10(np.e), bf_err * np.log10(np.e)))\n",
    "        return bf, bf_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def repeat_sample(sample, repeats):\n",
    "    sample = sample.copy()\n",
    "    for k in sample.keys():\n",
    "        sample[k] = np.repeat(sample[k], repeats)\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metropolis MC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model_m1:\n",
    "    trace_m1 = pm.sample(MET_STEPS, step=pm.Metropolis())\n",
    "pm.traceplot(trace_m1[::100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model_m2:\n",
    "    trace_m2 = pm.sample(MET_STEPS, step=pm.Metropolis())\n",
    "pm.traceplot(trace_m2[::100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_m1 = get_values_from_trace(model_m1, trace_m1, thin=100, burn=100)\n",
    "sample_m2 = get_values_from_trace(model_m2, trace_m2, thin=100, burn=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmenting with uniformly-drawn samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bayes_factor_uniform_aug(model_m1, sample_m1, model_m2, sample_m2, bootstrap=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmenting 10 more times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_m1_repeat = repeat_sample(sample_m1, 10)\n",
    "bayes_factor_uniform_aug(model_m1, sample_m1_repeat, model_m2, sample_m2, bootstrap=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmenting 100 more times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_m1_repeat = repeat_sample(sample_m1, 100)\n",
    "bayes_factor_uniform_aug(model_m1, sample_m1_repeat, model_m2, sample_m2, bootstrap=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
